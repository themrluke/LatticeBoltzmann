# timings_analysis.py

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import ScalarFormatter


def find_min_times(filepath, num_runs, max_threads):
    """
    Finds the minimum run time for each repeat of each number of threads.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): number of repeats for each number of threads
        max_threads (int): Maximum number of threads used

    Returns:
        min_times (list): list containing the fastest run for each number of threads
    """

    min_times = [] # Will hold the fastest run for each number of threads

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    # Check to ensure expected number of lines in file
    if len(lines) !=num_runs * max_threads:
        raise ValueError(f"Expected {num_runs * max_threads} lines, but found {len(lines)} in {filepath}")
    
    # Find the fastest run for each thread count
    for thread in range(max_threads):
        start_idx = thread * num_runs
        end_idx = start_idx + num_runs

        thread_times = [float(lines[i].strip()) for i in range(start_idx, end_idx)]

        min_times.append(min(thread_times)) # List now only inclues fastest run for each thread count

    return min_times


def find_min_times_mpi(filepath, num_runs, max_threads):
    """
    Finds the minimum run time for each repeat for each number of threads for MPI.
    We need a different function here because MPI will print N timing values for N threads,
    we want only the slowest value (thread that finishes last) to be considered when calculating
    the fasted repeat at each number of threads.
    
    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): number of repeats for each number of threads
        max_threads (int): Maximum number of threads used

    Returns:
        min_times (list): list containing the fastest run for each number of threads
    """

    min_times = []  # Holds the fastest run for each number of threads

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    current_index = 0

    # Find fastest run for each thread count
    for threads in range(1, max_threads + 1):

        run_times = []  # Stores the time for last process to finish for each thread count

        # Process each run for the current thread count
        for run in range(num_runs):
            # Extract the times for the current run
            run_timings = [
                float(lines[current_index + i].strip()) for i in range(threads)
            ]
            current_index += threads

            # We want the longest time (last process to finish)
            run_times.append(max(run_timings))

        # Find the minimum time across all runs for this thread count
        min_times.append(min(run_times))

    return min_times


def single_thread_times(filepath, num_runs):
    """
    For single threaded programs, we take the fastest value from the ones generated by the repeats.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): number of repeats for each number of threads

    Returns:
        min_times (int): Fastest run time
    """

    min_time = []
    # Read the timing data from the text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    # Quick check to ensure expected number of lines in file
    if len(lines) !=num_runs:
        raise ValueError(f"Expected {num_runs} lines, but found {len(lines)} in {filepath}")
    
    # Convert the lines to float and find the minimum value
    times = [float(line.strip()) for line in lines]
    min_time = min(times)

    return min_time


def find_avg_times(filepath, num_runs, max_threads):
    """
    Finds the average run time and standard deviation for each repeat of each number of threads.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): number of repeats for each number of threads
        max_threads (int): Maximum number of threads used

    Returns:
        avg_times (list): List of average times for each thread count
        std_errors (list): List of standard deviations of the mean for each thread count
    """
    avg_times = []  # Holds the average run times
    std_errors = []  # Holds the standard deviations of the mean

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    # Check to ensure expected number of lines in file
    if len(lines) != num_runs * max_threads:
        raise ValueError(f"Expected {num_runs * max_threads} lines, but found {len(lines)} in {filepath}")
    
    # Calculate average and standard deviation for each thread count
    for thread in range(max_threads):
        start_idx = thread * num_runs
        end_idx = start_idx + num_runs

        thread_times = [float(lines[i].strip()) for i in range(start_idx, end_idx)]

        avg_times.append(np.mean(thread_times))  # Average time
        std_errors.append(np.std(thread_times) / np.sqrt(num_runs))  # Standard deviation of the mean

    return avg_times, std_errors


def find_avg_times_mpi(filepath, num_runs, max_threads):
    """
    Finds the average run time and standard deviation for MPI.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): Number of repeats for each number of threads
        max_threads (int): Maximum number of threads used

    Returns:
        avg_times (list): List of average times for each thread count
        std_errors (list): List of standard deviations of the mean for each thread count
    """
    avg_times = []  # Holds the average run times
    std_errors = []  # Holds the standard deviations of the mean

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    current_index = 0

    for threads in range(1, max_threads + 1):
        run_times = []  # Stores the time for the slowest process in each run

        for run in range(num_runs):
            run_timings = [
                float(lines[current_index + i].strip()) for i in range(threads)
            ]
            current_index += threads
            run_times.append(max(run_timings))  # Use the slowest process time

        avg_times.append(np.mean(run_times))
        std_errors.append(np.std(run_times) / np.sqrt(num_runs))

    return avg_times, std_errors


def multi_threading_plot(numba_avg, numba_err, openmp_avg, openmp_err, mpi_avg, mpi_err, max_threads):
    """
    Line plots to show the speedup from using more threads.

    Arguments:
        numba_avg (list): Average time taken for program for different numbers of threads
        numba_err (list): Standard errors for Numba times
        openmp_times (list): Average time taken for program for different numbers of threads
        openmp_err (list): Standard errors for OpenMP times
        mpi_times (list): Average time taken for program for different numbers of threads
        mpi_err (list): Standard errors for MPI times
        max_threads (int): Maximum number of threads used
    """

    threads = np.arange(1, max_threads + 1)

    # Plotting the results
    plt.figure(figsize=(10, 6))
    plt.errorbar(threads, numba_avg, yerr=numba_err, label="Numba", linewidth=1.2, marker="o", markersize=4, capsize=3)
    plt.errorbar(threads, openmp_avg, yerr=openmp_err, label="OpenMP", linewidth=1.2, marker="s", markersize=4, capsize=3)
    plt.errorbar(threads, mpi_avg, yerr=mpi_err, label="MPI", linewidth=1.2, marker="^", markersize=4, capsize=3)
    plt.xlabel("Workers", fontweight='bold', fontsize=12)
    plt.ylabel("Time (s)", fontweight='bold', fontsize=12)
    plt.title("Multithreading Speed Up with Error Bars", fontsize=14, fontweight='bold')
    plt.yscale('log')
    #plt.xscale('log')

    # Set integer formatting for both axes
    ax = plt.gca()
    ax.yaxis.set_major_formatter(ScalarFormatter())
    ax.xaxis.set_major_formatter(ScalarFormatter())

    plt.legend()
    plt.grid(True, which="both", linewidth=0.5)  # Grid for both major and minor ticks
    plt.tight_layout()
    plt.savefig("line_plots.png", dpi=300)
    plt.close()


def bar_plot(standard_time, vectorised_time, cython_time, mpi_times, openmp_times, numba_times, numba_gpu_time):
    """
    Creates a bar plot comparing the execution times of standard, vectorized, and Cython implementations.

    Args:
        standard_time (float): Execution time for standard Python program
        vectorised_time (float): Execution time for vectorized Python program
        cython_time (float): Execution time for Cython program
    """

    openmp_1thread = openmp_times[0]
    openmp_8threads = openmp_times[7]
    openmp_28threads = openmp_times[27]

    numba_1thread = numba_times[0]
    numba_8threads = numba_times[7]
    numba_28threads = numba_times[27]

    mpi_1process = mpi_times[0]
    mpi_8processes = mpi_times[7]
    mpi_28processes = mpi_times[27]

    # Labels and times
    labels = [
        'Standard Python', 'Vectorized Python', 'Cython',
        'OpenMP 1 Thread', 'Numba 1 Thread', ' MPI 1 Process',
        'OpenMP 8 Threads', 'Numba 8 Threads', ' MPI 8 Processes',
        'OpenMP 28 Threads', 'Numba 28 Threads', ' MPI 28 Processes',
        'Numba GPU (4070TI)'
    ]
    times = [
        standard_time, vectorised_time, cython_time,
        openmp_1thread, numba_1thread, mpi_1process,
        openmp_8threads, numba_8threads, mpi_8processes,
        openmp_28threads, numba_28threads, mpi_28processes,
        numba_gpu_time
    ]

    # Create the bar plot
    plt.figure(figsize=(8, 6))
    bars = plt.bar(labels, times, width=0.75, align='center', zorder=3)
    plt.grid(axis='y', zorder=0, linewidth=1)
    plt.yscale('log')  # Logarithmic scale for the y-axis
    plt.ylim(0.1, 10**5)  # Adjust the starting and ending values of the y-axis
    plt.ylabel("Time (s)", fontweight='bold', fontsize=12)
    plt.title("Blue Crystal Timings", fontweight='bold', fontsize=14)

    # Rotate x-axis labels for better readability
    plt.xticks(rotation=45, ha='right', fontsize=10)  # Rotate 45 degrees and align to the right

    # Add the values inside the bars
    for bar, time in zip(bars, times):
        plt.text(bar.get_x() + bar.get_width() / 2.0, 0.4,  # Position inside the bar
                 f"{time:.2f}", ha='center', va='center', color='white', fontsize=10, fontweight='bold', rotation='vertical')
        
    plt.tight_layout()
    
    # Save the plot
    plt.savefig("bar_plot.png", dpi=300)
    plt.close()


def main():
    
    numba_times = find_min_times(filepath='numba/loop_timings_3200.txt', num_runs=5, max_threads=28)
    openmp_times = find_min_times(filepath='openmp/loop_timings_3200.txt', num_runs=5, max_threads=28)
    mpi_times = find_min_times_mpi(filepath='mpi/loop_timings_3200.txt', num_runs=5, max_threads=28)

    numba_avg, numba_err = find_avg_times(filepath='numba/loop_timings_3200.txt', num_runs=5, max_threads=28)
    openmp_avg, openmp_err = find_avg_times(filepath='openmp/loop_timings_3200.txt', num_runs=5, max_threads=28)
    mpi_avg, mpi_err = find_avg_times_mpi(filepath='mpi/loop_timings_3200.txt', num_runs=5, max_threads=28)

    standard_time = single_thread_times(filepath='standard_python/loop_timings.txt', num_runs=1)
    vectorised_time = single_thread_times(filepath='vectorised_python/loop_timings.txt', num_runs=10)
    cython_time = single_thread_times(filepath='cython/loop_timings_3200.txt', num_runs=10)
    numba_gpu_time = single_thread_times(filepath='numba_gpu/loop_timings_3200.txt', num_runs=5)

    multi_threading_plot(numba_avg, numba_err, openmp_avg, openmp_err, mpi_avg, mpi_err, 28)
    bar_plot(standard_time, vectorised_time, cython_time, mpi_times, openmp_times, numba_times, numba_gpu_time)

if __name__ == "__main__":
    main()