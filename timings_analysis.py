# timings_analysis.py

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import ScalarFormatter


def find_min_times(filepath, num_runs, max_threads):
    """
    Finds the minimum run time for each repeat of each number of threads.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): number of repeats for each number of threads
        max_threads (int): Maximum number of threads used

    Returns:
        min_times (list): list containing the fastest run for each number of threads
    """

    min_times = [] # Will hold the fastest run for each number of threads

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    # Check to ensure expected number of lines in file
    if len(lines) !=num_runs * max_threads:
        raise ValueError(f"Expected {num_runs * max_threads} lines, but found {len(lines)} in {filepath}")
    
    # Find the fastest run for each thread count
    for thread in range(max_threads):
        start_idx = thread * num_runs
        end_idx = start_idx + num_runs

        thread_times = [float(lines[i].strip()) for i in range(start_idx, end_idx)]

        min_times.append(min(thread_times)) # List now only inclues fastest run for each thread count

    return min_times


def find_min_times_mpi(filepath, num_runs, max_threads):
    """
    Finds the minimum run time for each repeat for each number of threads for MPI.
    We need a different function here because MPI will print N timing values for N threads,
    we want only the slowest value (thread that finishes last) to be considered when calculating
    the fasted repeat at each number of threads.
    
    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): number of repeats for each number of threads
        max_threads (int): Maximum number of threads used

    Returns:
        min_times (list): list containing the fastest run for each number of threads
    """

    min_times = []  # Holds the fastest run for each number of threads

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    current_index = 0

    # Find fastest run for each thread count
    for threads in range(1, max_threads + 1):

        run_times = []  # Stores the time for last process to finish for each thread count

        # Process each run for the current thread count
        for run in range(num_runs):
            # Extract the times for the current run
            run_timings = [
                float(lines[current_index + i].strip()) for i in range(threads)
            ]
            current_index += threads

            # We want the longest time (last process to finish)
            run_times.append(max(run_timings))

        # Find the minimum time across all runs for this thread count
        min_times.append(min(run_times))

    return min_times


def single_thread_times(filepath, num_runs):
    """
    For single threaded programs, we take the fastest value from the ones generated by the repeats.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): number of repeats for each number of threads

    Returns:
        min_times (int): Fastest run time
    """

    min_time = []
    # Read the timing data from the text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    # Quick check to ensure expected number of lines in file
    if len(lines) !=num_runs:
        raise ValueError(f"Expected {num_runs} lines, but found {len(lines)} in {filepath}")
    
    # Convert the lines to float and find the minimum value
    times = [float(line.strip()) for line in lines]
    min_time = min(times)

    return min_time


def find_avg_times(filepath, num_runs, max_threads):
    """
    Finds the average run time and standard deviation for each repeat of each number of threads.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): number of repeats for each number of threads
        max_threads (int): Maximum number of threads used

    Returns:
        avg_times (list): List of average times for each thread count
        std_errors (list): List of standard deviations of the mean for each thread count
    """
    avg_times = []  # Holds the average run times
    std_errors = []  # Holds the standard deviations of the mean

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    # Check to ensure expected number of lines in file
    if len(lines) != num_runs * max_threads:
        raise ValueError(f"Expected {num_runs * max_threads} lines, but found {len(lines)} in {filepath}")
    
    # Calculate average and standard deviation for each thread count
    for thread in range(max_threads):
        start_idx = thread * num_runs
        end_idx = start_idx + num_runs

        thread_times = [float(lines[i].strip()) for i in range(start_idx, end_idx)]

        avg_times.append(np.mean(thread_times))  # Average time
        std_errors.append(np.std(thread_times) / np.sqrt(num_runs))  # Standard deviation of the mean

    return avg_times, std_errors


def find_avg_times_mpi(filepath, num_runs, max_threads):
    """
    Finds the average run time and standard deviation for MPI.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): Number of repeats for each number of threads
        max_threads (int): Maximum number of threads used

    Returns:
        avg_times (list): List of average times for each thread count
        std_errors (list): List of standard deviations of the mean for each thread count
    """
    avg_times = []  # Holds the average run times
    std_errors = []  # Holds the standard deviations of the mean

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    current_index = 0

    for threads in range(1, max_threads + 1):
        run_times = []  # Stores the time for the slowest process in each run

        for run in range(num_runs):
            run_timings = [
                float(lines[current_index + i].strip()) for i in range(threads)
            ]
            current_index += threads
            run_times.append(max(run_timings))  # Use the slowest process time

        avg_times.append(np.mean(run_times))
        std_errors.append(np.std(run_times) / np.sqrt(num_runs))

    return avg_times, std_errors


def find_avg_times_system_sizes(filepath, num_runs, system_sizes):
    """
    Finds the average run time and standard deviation for each system size.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): Number of repeats for each system size
        system_sizes (list): List of system sizes

    Returns:
        avg_times (list): List of average times for each system size
        std_errors (list): List of standard deviations of the mean for each system size
    """
    avg_times = []  # Holds the average run times for each system size
    std_errors = []  # Holds the standard deviation of the mean for each system size

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    # Check to ensure expected number of lines in file
    if len(lines) != num_runs * len(system_sizes):
        raise ValueError(f"Expected {num_runs * len(system_sizes)} lines, but found {len(lines)} in {filepath}")

    # Calculate average and standard deviation for each system size
    for i, size in enumerate(system_sizes):
        start_idx = i * num_runs
        end_idx = start_idx + num_runs

        size_times = [float(lines[j].strip()) for j in range(start_idx, end_idx)]

        avg_times.append(np.mean(size_times))  # Average time
        std_errors.append(np.std(size_times) / np.sqrt(num_runs))  # Standard deviation of the mean

    return avg_times, std_errors


def find_avg_times_system_sizes_mpi(filepath, num_runs, system_sizes, num_processes):
    """
    Finds the average run time and standard deviation for each system size for MPI runs.

    For MPI runs, where there are `num_processes` outputs per run, we consider only the slowest
    time (representing the last process to finish) for the average calculation.

    Arguments:
        filepath (str): Path to the text file containing timing data
        num_runs (int): Number of repeats for each system size
        system_sizes (list): List of system sizes
        num_processes (int): Number of processes used in the MPI runs

    Returns:
        avg_times (list): List of average times for each system size
        std_errors (list): List of standard deviations of the mean for each system size
    """
    avg_times = []  # Holds the average run times for each system size
    std_errors = []  # Holds the standard deviation of the mean for each system size

    # Read data from text file
    with open(filepath, "r") as file:
        lines = file.readlines()

    # Check to ensure expected number of lines in file
    expected_lines = num_runs * len(system_sizes) * num_processes
    if len(lines) != expected_lines:
        raise ValueError(f"Expected {expected_lines} lines, but found {len(lines)} in {filepath}")

    current_index = 0

    # Calculate average and standard deviation for each system size
    for i, size in enumerate(system_sizes):
        size_times = []  # Store the slowest time for each run of the current system size

        for run in range(num_runs):
            # Extract times for the current run (one value per process)
            run_timings = [
                float(lines[current_index + process].strip()) for process in range(num_processes)
            ]
            current_index += num_processes

            # Append the slowest time (last process to finish)
            size_times.append(max(run_timings))

        # Calculate average and standard deviation of the slowest times
        avg_times.append(np.mean(size_times))
        std_errors.append(np.std(size_times) / np.sqrt(num_runs))

    return avg_times, std_errors


def multi_threading_plot(numba_avg, numba_err, openmp_avg, openmp_err, mpi_avg, mpi_err, max_threads):
    """
    Line plots to show the speedup from using more threads.

    Arguments:
        numba_avg (list): Average time taken for program for different numbers of threads
        numba_err (list): Standard errors for Numba times
        openmp_times (list): Average time taken for program for different numbers of threads
        openmp_err (list): Standard errors for OpenMP times
        mpi_times (list): Average time taken for program for different numbers of threads
        mpi_err (list): Standard errors for MPI times
        max_threads (int): Maximum number of threads used
    """

    threads = np.arange(1, max_threads + 1)

    # Calculate speedup: Speedup = T(1 worker) / T(n workers)
    numba_speedup = [numba_avg[0] / t for t in numba_avg]
    numba_speedup_err = [numba_err[0] / t for t in numba_avg]  # Propagate error (approximation)

    openmp_speedup = [openmp_avg[0] / t for t in openmp_avg]
    openmp_speedup_err = [openmp_err[0] / t for t in openmp_avg]  # Propagate error (approximation)

    mpi_speedup = [mpi_avg[0] / t for t in mpi_avg]
    mpi_speedup_err = [mpi_err[0] / t for t in mpi_avg]  # Propagate error (approximation)

    # Plotting the results
    plt.figure(figsize=(10, 6))
    plt.errorbar(threads, numba_speedup, yerr=numba_speedup_err, label="Numba", linewidth=1.2, marker="o", markersize=4, capsize=3)
    plt.errorbar(threads, openmp_speedup, yerr=openmp_speedup_err, label="OpenMP", linewidth=1.2, marker="s", markersize=4, capsize=3)
    plt.errorbar(threads, mpi_speedup, yerr=mpi_speedup_err, label="MPI", linewidth=1.2, marker="^", markersize=4, capsize=3)

    plt.xlabel("Workers", fontweight='bold', fontsize=12)
    plt.ylabel("Speedup", fontweight='bold', fontsize=12)
    plt.title("Speedup vs. Workers", fontsize=14, fontweight='bold')
    plt.yscale('linear')  # Speedup is typically displayed on a linear scale
    plt.xscale('linear')

    # Set integer formatting for both axes
    ax = plt.gca()
    ax.yaxis.set_major_formatter(ScalarFormatter())
    ax.xaxis.set_major_formatter(ScalarFormatter())

    plt.legend()
    plt.grid(True, which="both", linewidth=0.5)  # Grid for both major and minor ticks
    plt.tight_layout()
    plt.savefig("speedup_plot.png", dpi=300)
    plt.close()


def system_size_plot(system_sizes, avg_times, std_errors, implementation_name):
    """
    Line plot to show execution time vs. system size for a given implementation.

    Arguments:
        system_sizes (list): List of system sizes (e.g., num_x values).
        avg_times (list): List of average execution times corresponding to the system sizes.
        std_errors (list): List of standard deviations of the mean for the execution times.
        implementation_name (str): Name of the implementation (e.g., "OpenMP").
    """
    plt.figure(figsize=(10, 6))
    plt.errorbar(
        system_sizes, avg_times, yerr=std_errors, label=implementation_name,
        linewidth=1.2, marker="o", markersize=4, capsize=3
    )
    plt.xlabel("System Size (num_x)", fontweight='bold', fontsize=12)
    plt.ylabel("Time (s)", fontweight='bold', fontsize=12)
    plt.title(f"{implementation_name}: Execution Time vs. System Size", fontsize=14, fontweight='bold')
    #plt.yscale('log')  # Log scale for execution time
    #plt.xscale('log')  # Log scale for system size

    # Set integer formatting for both axes
    ax = plt.gca()
    ax.yaxis.set_major_formatter(ScalarFormatter())
    ax.xaxis.set_major_formatter(ScalarFormatter())

    plt.legend()
    plt.grid(True, which="both", linewidth=0.5)
    plt.tight_layout()
    plt.savefig(f"{implementation_name}_system_size_plot.png", dpi=300)
    plt.close()


def bar_plot(standard_time, vectorised_time, cython_time, mpi_times, openmp_times, numba_times, numba_gpu_time):
    """
    Creates a bar plot comparing the execution times of standard, vectorized, and Cython implementations.

    Args:
        standard_time (float): Execution time for standard Python program
        vectorised_time (float): Execution time for vectorized Python program
        cython_time (float): Execution time for Cython program
    """

    openmp_1thread = openmp_times[0]
    openmp_8threads = openmp_times[7]
    openmp_28threads = openmp_times[27]

    numba_1thread = numba_times[0]
    numba_8threads = numba_times[7]
    numba_28threads = numba_times[27]

    mpi_1process = mpi_times[0]
    mpi_8processes = mpi_times[7]
    mpi_28processes = mpi_times[27]

    # Labels and times
    labels = [
        'Standard Python', 'Vectorized Python', 'Cython',
        'OpenMP 1 Thread', 'Numba 1 Thread', ' MPI 1 Process',
        'OpenMP 8 Threads', 'Numba 8 Threads', ' MPI 8 Processes',
        'OpenMP 28 Threads', 'Numba 28 Threads', ' MPI 28 Processes',
        'Numba GPU (4070TI)'
    ]
    times = [
        standard_time, vectorised_time, cython_time,
        openmp_1thread, numba_1thread, mpi_1process,
        openmp_8threads, numba_8threads, mpi_8processes,
        openmp_28threads, numba_28threads, mpi_28processes,
        numba_gpu_time
    ]

    # Create the bar plot
    plt.figure(figsize=(8, 6))
    bars = plt.bar(labels, times, width=0.75, align='center', zorder=3)
    plt.grid(axis='y', zorder=0, linewidth=1)
    plt.yscale('log')  # Logarithmic scale for the y-axis
    plt.ylim(0.1, 10**5)  # Adjust the starting and ending values of the y-axis
    plt.ylabel("Time (s)", fontweight='bold', fontsize=12)
    plt.title("Blue Crystal Timings", fontweight='bold', fontsize=14)

    # Rotate x-axis labels for better readability
    plt.xticks(rotation=45, ha='right', fontsize=10)  # Rotate 45 degrees and align to the right

    # Add the values inside the bars
    for bar, time in zip(bars, times):
        plt.text(bar.get_x() + bar.get_width() / 2.0, 0.4,  # Position inside the bar
                 f"{time:.2f}", ha='center', va='center', color='white', fontsize=10, fontweight='bold', rotation='vertical')

    plt.tight_layout()

    # Save the plot
    plt.savefig("bar_plot.png", dpi=300)
    plt.close()


def main():

    # Minimum times across all runs for each thread count
    numba_min_threads = find_min_times(filepath='numba/loop_timings_speedup.txt', num_runs=5, max_threads=28)
    openmp_min_threads = find_min_times(filepath='openmp/loop_timings_speedup.txt', num_runs=5, max_threads=28)
    mpi_min_threads = find_min_times_mpi(filepath='mpi/loop_timings_speedup.txt', num_runs=5, max_threads=28)

    # Average times across all runs for each thread count
    numba_avg, numba_err = find_avg_times(filepath='numba/loop_timings_speedup.txt', num_runs=5, max_threads=28)
    openmp_avg, openmp_err = find_avg_times(filepath='openmp/loop_timings_speedup.txt', num_runs=5, max_threads=28)
    mpi_avg, mpi_err = find_avg_times_mpi(filepath='mpi/loop_timings_speedup.txt', num_runs=5, max_threads=28)

    # Minimum time across all runs for single threaded programs
    standard_min_time = single_thread_times(filepath='standard_python/loop_timings_3200.txt', num_runs=1)
    vectorised_min_time = single_thread_times(filepath='vectorised_python/loop_timings_3200.txt', num_runs=10)
    cython_min_time = single_thread_times(filepath='cython/loop_timings_3200.txt', num_runs=10)
    numbagpu_min_time = single_thread_times(filepath='numba_gpu/loop_timings_3200.txt', num_runs=5)

    multi_threading_plot(numba_avg, numba_err, openmp_avg, openmp_err, mpi_avg, mpi_err, 28)
    bar_plot(standard_min_time, vectorised_min_time, cython_min_time, mpi_min_threads, openmp_min_threads, numba_min_threads, numbagpu_min_time)


    system_sizes = [ # System sizes
        120, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 2000, 2400, 2800, 3200, 4000, 4800, 5600, 6400
    ]

    num_runs = 1  # Number of repeats for each system size

    # # Parse timing data for system sizes
    # numba_avg_sizes, numba_err_sizes = find_avg_times_system_sizes(
    #     filepath='numba/loop_timings.txt', num_runs=num_runs, system_sizes=system_sizes
    # )
    # openmp_avg_sizes, openmp_err_sizes = find_avg_times_system_sizes(
    #     filepath='openmp/loop_timings.txt', num_runs=num_runs, system_sizes=system_sizes
    # )
    # mpi_avg_sizes, mpi_err_sizes = find_avg_times_system_sizes_mpi(
    #     filepath='mpi/loop_timings.txt', num_runs=num_runs, system_sizes=system_sizes, num_processes=8
    # )
    numbagpu_avg_sizes, numbagpu_err_sizes = find_avg_times_system_sizes(
        filepath='numba_gpu/loop_timings_sizes.txt', num_runs=num_runs, system_sizes=system_sizes
    )

    # # Generate system size scaling plots
    # system_size_plot(system_sizes, numba_avg_sizes, numba_err_sizes, "Numba")
    # system_size_plot(system_sizes, openmp_avg_sizes, openmp_err_sizes, "OpenMP")
    # system_size_plot(system_sizes, mpi_avg_sizes, mpi_err_sizes, "MPI")
    system_size_plot(system_sizes, numbagpu_avg_sizes, numbagpu_err_sizes, "Numba_GPU")


if __name__ == "__main__":
    main()